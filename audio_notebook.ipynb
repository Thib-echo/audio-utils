{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutagen.mp3 import MP3\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import librosa\n",
    "import shutil\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First identify merged files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcription_data(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    transcription_file = file_path.with_stem(file_path.stem + '_segments_data').with_suffix('.json')\n",
    "    if transcription_file.exists():\n",
    "        with open(transcription_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return []\n",
    "\n",
    "def identify_merged_files(folder_path, gap_threshold=30):\n",
    "    merged_files = []\n",
    "    folder_path = Path(folder_path)\n",
    "    end_conversation_words = [\"au revoir\", \"bon courage\", \"bonne soirée\", \"bonne jounrée\"]\n",
    "\n",
    "    for audio_file in folder_path.rglob('*.mp3'):\n",
    "        transcription_data = read_transcription_data(audio_file)\n",
    "        merged_timestamps = []\n",
    "        last_bonjour_time = -gap_threshold  # Initialize to a value outside the gap threshold\n",
    "        end_conversation_detected = False\n",
    "\n",
    "        for segment in transcription_data:\n",
    "            segment_text = segment['text'].lower().strip()\n",
    "            segment_start = float(segment['start'])\n",
    "\n",
    "            # Check for end-of-conversation words\n",
    "            if any(re.search(r'\\b' + re.escape(end_word) + r'\\b', segment_text) for end_word in end_conversation_words):\n",
    "                end_conversation_detected = True\n",
    "\n",
    "            # Check for \"bonjour\" occurrences\n",
    "            if any(word in segment_text for word in ['bonjour', \"bon jour\"]):\n",
    "                if (segment_start > 10 or (segment_start <= 10 and end_conversation_detected)) and (segment_start - last_bonjour_time > gap_threshold):\n",
    "                    merged_timestamps.append(segment_start)\n",
    "                    last_bonjour_time = segment_start\n",
    "                end_conversation_detected = False  # Reset for next segments\n",
    "\n",
    "        if merged_timestamps:\n",
    "            merged_files.append((str(audio_file), merged_timestamps))\n",
    "\n",
    "    return merged_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('..\\\\audio_database\\\\raw_mp3_test_transcription\\\\2023_1_15_21_35_18_ch30\\\\2023_1_15_21_35_18_ch30.mp3',\n",
       "  [6.36, 152.59, 222.8]),\n",
       " ('..\\\\audio_database\\\\raw_mp3_test_transcription\\\\2023_1_9_7_27_59_ch30\\\\2023_1_9_7_27_59_ch30.mp3',\n",
       "  [107.23])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"../audio_database/raw_mp3_test_transcription/\"\n",
    "merged_files = identify_merged_files(folder_path)\n",
    "merged_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut and save audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(file_path, start_sample, end_sample, sr):\n",
    "    \"\"\" Split the audio file at the specified sample range \"\"\"\n",
    "    y, _ = librosa.load(file_path, sr=None, offset=start_sample/sr, duration=(end_sample-start_sample)/sr)\n",
    "    return y\n",
    "\n",
    "def format_filename(timestamp, original_stem):\n",
    "    file_name_components = [\n",
    "        str(timestamp.year),\n",
    "        str(timestamp.month),\n",
    "        str(timestamp.day),\n",
    "        str(timestamp.hour),\n",
    "        str(timestamp.minute),\n",
    "        str(timestamp.second),\n",
    "        original_stem.split('_')[-1]\n",
    "    ]\n",
    "    file_name = '_'.join(file_name_components)\n",
    "\n",
    "    return f\"{file_name}.mp3\"\n",
    "\n",
    "def cut_and_save_audio_files(raw_audio_folder, merged_files):\n",
    "    raw_audio_folder = Path(raw_audio_folder)\n",
    "\n",
    "    for file_path, cutting_times in merged_files:\n",
    "        file_path = Path(file_path)\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "        # Initial start sample for the first segment\n",
    "        prev_cut_sample = 0\n",
    "        original_stem = file_path.stem\n",
    "\n",
    "        for _, cut_time in enumerate(cutting_times):\n",
    "            cut_sample = int(cut_time * sr)\n",
    "            audio_segment = split_audio(file_path, prev_cut_sample, cut_sample, sr)\n",
    "\n",
    "            # Determine new file name and title\n",
    "            audio = MP3(file_path)\n",
    "            title = audio['TIT2'][0] if 'TIT2' in audio else 'Unknown'\n",
    "            start_timestamp, end_timestamp = parse_timestamp_from_title(title)\n",
    "            new_start_timestamp = start_timestamp + pd.to_timedelta(prev_cut_sample / sr, unit='s')\n",
    "            new_end_timestamp = start_timestamp + pd.to_timedelta(cut_sample / sr, unit='s')\n",
    "            new_file_name = format_filename(new_start_timestamp, original_stem)\n",
    "            new_title = f\"{new_start_timestamp.strftime('%d/%m/%Y %H:%M:%S')} - {new_end_timestamp.strftime('%d/%m/%Y %H:%M:%S')}\"\n",
    "\n",
    "            # Save the audio segment\n",
    "            segment_file_path = raw_audio_folder / new_file_name\n",
    "            sf.write(segment_file_path, audio_segment, sr)\n",
    "\n",
    "            # Update metadata for the segment\n",
    "            copy_metadata(file_path, segment_file_path, new_title)\n",
    "\n",
    "            prev_cut_sample = cut_sample\n",
    "\n",
    "        # Handle the last segment from the last cut to the end of the file\n",
    "        last_segment = split_audio(file_path, prev_cut_sample, len(y), sr)\n",
    "        new_start_timestamp = start_timestamp + pd.to_timedelta(prev_cut_sample / sr, unit='s')\n",
    "        new_file_name = format_filename(new_start_timestamp, original_stem)\n",
    "        last_segment_file_path = raw_audio_folder / new_file_name\n",
    "        new_title = f\"{new_start_timestamp.strftime('%d/%m/%Y %H:%M:%S')} - {end_timestamp.strftime('%d/%m/%Y %H:%M:%S')}\"\n",
    "        sf.write(last_segment_file_path, last_segment, sr)\n",
    "\n",
    "        # Update metadata for the last segment\n",
    "        copy_metadata(file_path, last_segment_file_path, new_title)\n",
    "\n",
    "        # Optionally delete the original file's transcription folder\n",
    "        shutil.rmtree(file_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_audio_folder = \"../audio_database/raw_mp3_test/\"\n",
    "cut_and_save_audio_files(raw_audio_folder, merged_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to rerun transcribe_all on those new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\transcribe_all.py --source_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test\\\" --dest_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test_transcription\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a raw_mp3_database containing unmerged file, the next step is to identify files belonging to the same conversation and fuse them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then create audio dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_in_timeframe(transcription_data, words, start_time, end_time):\n",
    "    for segment in transcription_data:\n",
    "        segment_text = segment['text'].lower()\n",
    "        segment_start = segment['start']\n",
    "        if start_time <= segment_start <= end_time:\n",
    "            if any(re.search(r'\\b' + re.escape(word) + r'\\b', segment_text) for word in words):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# def create_audio_database(folder_path):\n",
    "#     folder_path = Path(folder_path)\n",
    "#     data = []\n",
    "\n",
    "#     for audio_file in folder_path.rglob('*.mp3'):\n",
    "#         try:\n",
    "#             audio = MP3(audio_file)\n",
    "#             title = audio['TIT2'][0] if 'TIT2' in audio else 'Unknown'\n",
    "#             start_timestamp, end_timestamp = parse_timestamp_from_title(title)\n",
    "#             audio_length = audio.info.length\n",
    "\n",
    "#             transcription_path = audio_file.with_stem(audio_file.stem + '_transcription').with_suffix('.txt')\n",
    "#             # words_found = check_words_in_transcription(transcription_path, [\"bonjour\", \"au revoir\"])\n",
    "\n",
    "#             transcription_data = read_transcription_data(audio_file)\n",
    "\n",
    "#             is_start_file = check_word_in_timeframe(transcription_data, \"bonjour\", 0, 10)\n",
    "#             is_end_file = check_word_in_timeframe(transcription_data, \"au revoir\", max(0, audio_length - 10), audio_length)\n",
    "#             is_complete = is_start_file and is_end_file\n",
    "\n",
    "#             data.append({\n",
    "#                 \"File Name\": audio_file.stem,\n",
    "#                 \"File Path\": str(audio_file),\n",
    "#                 \"Transcription Path\": str(transcription_path) if transcription_path.exists() else None,\n",
    "#                 \"Start Timestamp\": start_timestamp,\n",
    "#                 \"End Timestamp\": end_timestamp,\n",
    "#                 \"Audio Length\": audio_length,\n",
    "#                 \"Is End File\": is_end_file,\n",
    "#                 \"Is Start File\": is_start_file,\n",
    "#                 \"Is Complete\": is_complete,\n",
    "#                 \"Precedent File\": None,\n",
    "#                 \"Next File\": None\n",
    "#             })\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing file {audio_file}: {e}\")\n",
    "\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "def create_audio_database(folder_path):\n",
    "    folder_path = Path(folder_path)\n",
    "    data = []\n",
    "    end_conversation_words = [\"au revoir\", \"bon courage\", \"bonne soirée\", \"bonne journée\"]\n",
    "\n",
    "    for audio_file in folder_path.rglob('*.mp3'):\n",
    "        try:\n",
    "            audio = MP3(audio_file)\n",
    "            title = audio['TIT2'][0] if 'TIT2' in audio else 'Unknown'\n",
    "            start_timestamp, end_timestamp = parse_timestamp_from_title(title)\n",
    "            audio_length = audio.info.length\n",
    "\n",
    "            transcription_path = audio_file.with_stem(audio_file.stem + '_transcription').with_suffix('.txt')\n",
    "            transcription_data = read_transcription_data(audio_file)\n",
    "\n",
    "            is_start_file = check_word_in_timeframe(transcription_data, [\"bonjour\", \"bon jour\"], 0, 10)\n",
    "            is_end_file = check_word_in_timeframe(transcription_data, end_conversation_words, max(0, audio_length - 10), audio_length)\n",
    "            is_complete = is_start_file and is_end_file\n",
    "\n",
    "            # If the file is complete, set is_start_file and is_end_file to False\n",
    "            if is_complete:\n",
    "                is_start_file = False\n",
    "                is_end_file = False\n",
    "\n",
    "            data.append({\n",
    "                \"File Name\": audio_file.stem,\n",
    "                \"File Path\": str(audio_file),\n",
    "                \"Transcription Path\": str(transcription_path) if transcription_path.exists() else None,\n",
    "                \"Start Timestamp\": start_timestamp,\n",
    "                \"End Timestamp\": end_timestamp,\n",
    "                \"Audio Length\": audio_length,\n",
    "                \"Is End File\": is_end_file,\n",
    "                \"Is Start File\": is_start_file,\n",
    "                \"Is Complete\": is_complete,\n",
    "                \"Precedent File\": None,\n",
    "                \"Next File\": None\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {audio_file}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Path</th>\n",
       "      <th>Transcription Path</th>\n",
       "      <th>Start Timestamp</th>\n",
       "      <th>End Timestamp</th>\n",
       "      <th>Audio Length</th>\n",
       "      <th>Is End File</th>\n",
       "      <th>Is Start File</th>\n",
       "      <th>Is Complete</th>\n",
       "      <th>Precedent File</th>\n",
       "      <th>Next File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023_1_15_10_5_41_ch30</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>2023-01-15 10:05:41</td>\n",
       "      <td>2023-01-15 10:09:41</td>\n",
       "      <td>240.408</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023_1_15_18_40_13_ch30</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>2023-01-15 18:40:13</td>\n",
       "      <td>2023-01-15 18:41:13</td>\n",
       "      <td>59.760</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023_1_15_18_59_42_ch30</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>2023-01-15 18:59:42</td>\n",
       "      <td>2023-01-15 19:02:05</td>\n",
       "      <td>141.660</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023_1_15_20_11_51_ch30</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>2023-01-15 20:11:51</td>\n",
       "      <td>2023-01-15 20:14:19</td>\n",
       "      <td>147.486</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023_1_15_20_14_19_ch30</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>..\\audio_database\\raw_mp3_test_transcription\\2...</td>\n",
       "      <td>2023-01-15 20:14:19</td>\n",
       "      <td>2023-01-15 20:14:55</td>\n",
       "      <td>35.142</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Name                                          File Path  \\\n",
       "0   2023_1_15_10_5_41_ch30  ..\\audio_database\\raw_mp3_test_transcription\\2...   \n",
       "1  2023_1_15_18_40_13_ch30  ..\\audio_database\\raw_mp3_test_transcription\\2...   \n",
       "2  2023_1_15_18_59_42_ch30  ..\\audio_database\\raw_mp3_test_transcription\\2...   \n",
       "3  2023_1_15_20_11_51_ch30  ..\\audio_database\\raw_mp3_test_transcription\\2...   \n",
       "4  2023_1_15_20_14_19_ch30  ..\\audio_database\\raw_mp3_test_transcription\\2...   \n",
       "\n",
       "                                  Transcription Path     Start Timestamp  \\\n",
       "0  ..\\audio_database\\raw_mp3_test_transcription\\2... 2023-01-15 10:05:41   \n",
       "1  ..\\audio_database\\raw_mp3_test_transcription\\2... 2023-01-15 18:40:13   \n",
       "2  ..\\audio_database\\raw_mp3_test_transcription\\2... 2023-01-15 18:59:42   \n",
       "3  ..\\audio_database\\raw_mp3_test_transcription\\2... 2023-01-15 20:11:51   \n",
       "4  ..\\audio_database\\raw_mp3_test_transcription\\2... 2023-01-15 20:14:19   \n",
       "\n",
       "        End Timestamp  Audio Length  Is End File  Is Start File  Is Complete  \\\n",
       "0 2023-01-15 10:09:41       240.408        False          False         True   \n",
       "1 2023-01-15 18:41:13        59.760        False           True        False   \n",
       "2 2023-01-15 19:02:05       141.660        False          False         True   \n",
       "3 2023-01-15 20:14:19       147.486        False          False         True   \n",
       "4 2023-01-15 20:14:55        35.142        False           True        False   \n",
       "\n",
       "  Precedent File Next File  \n",
       "0           None      None  \n",
       "1           None      None  \n",
       "2           None      None  \n",
       "3           None      None  \n",
       "4           None      None  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "folder_path = \"../audio_database/raw_mp3_test_transcription/\"\n",
    "df = create_audio_database(folder_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroup associated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_associated_files(df, time_delta=20):\n",
    "    associated_files = []\n",
    "\n",
    "    # Filter DataFrame for start, other, and end files\n",
    "    start_files = df[df['Is Start File']]\n",
    "    other_files = df[~df['Is End File'] & ~df['Is Start File']]\n",
    "    end_files = df[df['Is End File']]\n",
    "\n",
    "    for idx, start_row in start_files.iterrows():\n",
    "        end_time_beginning = start_row['End Timestamp']\n",
    "        if pd.isnull(end_time_beginning):\n",
    "            continue\n",
    "\n",
    "        # First check in other_files\n",
    "        other_file_found = None\n",
    "        for _, other_row in other_files.iterrows():\n",
    "            start_time_other = other_row['Start Timestamp']\n",
    "            if pd.isnull(start_time_other):\n",
    "                continue\n",
    "\n",
    "            if 0 <= (start_time_other - end_time_beginning).total_seconds() <= time_delta:\n",
    "                other_file_found = other_row\n",
    "                break\n",
    "\n",
    "        # If an other_file is found, check for a corresponding file in file_ends\n",
    "        end_file_found = None\n",
    "        if other_file_found is not None:\n",
    "            end_time_other = other_file_found['End Timestamp']\n",
    "            for _, end_row in end_files.iterrows():\n",
    "                start_time_ending = end_row['Start Timestamp']\n",
    "                if pd.isnull(start_time_ending):\n",
    "                    continue\n",
    "\n",
    "                if 0 <= (start_time_ending - end_time_other).total_seconds() <= time_delta:\n",
    "                    end_file_found = end_row\n",
    "                    break\n",
    "\n",
    "            if end_file_found is not None:\n",
    "                associated_files.append((start_row['File Path'], other_file_found['File Path'], end_file_found['File Path']))\n",
    "            else:\n",
    "                associated_files.append((start_row['File Path'], other_file_found['File Path']))\n",
    "\n",
    "        # If no other_file is found, check directly in file_ends\n",
    "        elif other_file_found is None:\n",
    "            for _, end_row in end_files.iterrows():\n",
    "                start_time_ending = end_row['Start Timestamp']\n",
    "                if pd.isnull(start_time_ending):\n",
    "                    continue\n",
    "\n",
    "                if 0 <= (start_time_ending - end_time_beginning).total_seconds() <= time_delta:\n",
    "                    associated_files.append((start_row['File Path'], end_row['File Path']))\n",
    "                    break\n",
    "\n",
    "    return associated_files\n",
    "\n",
    "associated_files = find_associated_files(df)\n",
    "for files in associated_files:\n",
    "    print(f\"Associated files: {', '.join(files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy grouped files and merge the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_associated_files_to_group_folder(associated_files, df, raw_audio_folder):\n",
    "    raw_audio_folder = Path(raw_audio_folder)\n",
    "\n",
    "    for group in associated_files:\n",
    "        # Create a unique folder for each group\n",
    "\n",
    "        audio_files = []\n",
    "        start_timestamp = None\n",
    "        end_timestamp = None\n",
    "\n",
    "        for file_path in group:        \n",
    "            # Add file to list for merging\n",
    "            audio_files.append(file_path)\n",
    "\n",
    "            # Extract timestamps for merged file metadata\n",
    "            file_info = df[df['File Path'] == file_path].iloc[0]\n",
    "            if start_timestamp is None or file_info['Start Timestamp'] < start_timestamp:\n",
    "                start_timestamp = file_info['Start Timestamp']\n",
    "            if end_timestamp is None or file_info['End Timestamp'] > end_timestamp:\n",
    "                end_timestamp = file_info['End Timestamp']\n",
    "\n",
    "            # Delete original audio\n",
    "            original_audio = raw_audio_folder / Path(file_path).name\n",
    "            original_audio.unlink()\n",
    "\n",
    "        # Merge and save audio\n",
    "        merged_audio, sample_rate = merge_audios(audio_files)\n",
    "        merged_file_path = raw_audio_folder / Path(audio_files[0]).name\n",
    "        sf.write(merged_file_path, merged_audio, sample_rate)\n",
    "        \n",
    "        # Copy metadata from the beginning file to the merged file\n",
    "        start_timestamp = start_timestamp.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        end_timestamp = end_timestamp.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "        new_title = f\"{start_timestamp} - {end_timestamp}\"\n",
    "        copy_metadata(group[0], merged_file_path, new_title)\n",
    "\n",
    "        # Delete old transcription folder\n",
    "        for file_path in group:\n",
    "            shutil.rmtree(Path(file_path).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "raw_audio_folder = \"../audio_database/raw_mp3_test/\"\n",
    "copy_associated_files_to_group_folder(associated_files, df, raw_audio_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun again transcribe_all on the final new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!python .\\transcribe_all.py --source_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test\\\" --dest_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test_transcription\\\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
