{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "from mutagen.mp3 import MP3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from audio_utils import *\n",
    "import logging\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "END_OF_CONV_WORDS = [\"au revoir\", \"bon courage\", \"bonne soirée\", \"bonne jounrée\", \"bye\", \"goodbye\"]\n",
    "START_OF_CONV_WORDS = [\"bonjour\", \"bon jour\", \"hello\", \"hi\", \"good morning\"]\n",
    "DATA_FOLDER = Path(\"../audio_database/ch30_test/\")\n",
    "\n",
    "transcription_folder = DATA_FOLDER / 'raw_transcriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "\n",
    "def load_audio(file_path):\n",
    "    # Loading audio file with librosa\n",
    "    audio, sr = librosa.load(str(file_path), sr=None)\n",
    "    return audio, sr\n",
    "\n",
    "def reduce_noise(audio, sr):\n",
    "    # Reduce noise using the noisereduce library\n",
    "    return nr.reduce_noise(y=audio, sr=sr)\n",
    "\n",
    "def normalize_volume(audio):\n",
    "    # Normalize audio to have a consistent volume\n",
    "    rms = np.sqrt(np.mean(audio**2))\n",
    "    return audio / rms\n",
    "\n",
    "def segment_audio(audio, sr, segment_length=5):\n",
    "    # Split audio into 5-second segments\n",
    "    buffer = segment_length * sr\n",
    "    segments = [audio[i:i+buffer] for i in range(0, len(audio), buffer)]\n",
    "    return segments\n",
    "\n",
    "def resample_audio(audio, sr, target_sr=16000):\n",
    "    # Resample audio to the target sample rate (e.g., 16kHz)\n",
    "    return librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "def final_preprocessing(audio, sr):\n",
    "    # Additional preprocessing steps if needed\n",
    "    # For Faster Whisper, this might involve format conversion\n",
    "    # This is just a placeholder function\n",
    "    return audio\n",
    "\n",
    "def preprocess_audio(file_path, output_file_path):\n",
    "    audio, sr = load_audio(file_path)\n",
    "    audio = reduce_noise(audio, sr)\n",
    "    audio = normalize_volume(audio)\n",
    "    # Only use segmentation if necessary\n",
    "    # audio_segments = segment_audio(audio, sr)\n",
    "    audio = resample_audio(audio, sr)\n",
    "    audio = final_preprocessing(audio, sr)\n",
    "    save_audio_segment(output_file_path, audio, sr)\n",
    "    return audio\n",
    "\n",
    "\n",
    "data_path = Path('../audio_database/test_preprocess/preprocessed_first_transcription/')\n",
    "for file in data_path.glob('*.mp3'):\n",
    "    preprocess_audio(file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_silence_with_crossfade(audio_path, output_path, silence_thresh=-50, min_silence_len=1000, silence_chunk_len=500, crossfade_len=100):\n",
    "    \"\"\"\n",
    "    Removes or shortens silence from an audio file with crossfade for smoother transitions.\n",
    "    \n",
    "    :param audio_path: Path to the input audio file.\n",
    "    :param output_path: Path to save the modified audio file.\n",
    "    :param silence_thresh: The threshold in dBFS considered as silence. Default is -50 dBFS.\n",
    "    :param min_silence_len: Minimum length of silence to be considered for removal in milliseconds. Default is 1000 ms.\n",
    "    :param silence_chunk_len: Length to which silence should be reduced in milliseconds. Default is 500 ms.\n",
    "    :param crossfade_len: Length of the crossfade in milliseconds. Default is 50 ms.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # Detect non-silent chunks\n",
    "    nonsilent_chunks = silence.detect_nonsilent(\n",
    "        audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh\n",
    "    )\n",
    "\n",
    "    # Process each chunk with crossfade\n",
    "    processed_audio = AudioSegment.silent(duration=0)\n",
    "    for start_i, end_i in nonsilent_chunks:\n",
    "        chunk = audio[start_i:end_i]\n",
    "        if len(processed_audio) > 0:\n",
    "            processed_audio = processed_audio.append(chunk, crossfade=crossfade_len)\n",
    "        else:\n",
    "            processed_audio = chunk\n",
    "        processed_audio += AudioSegment.silent(duration=silence_chunk_len)\n",
    "\n",
    "    # Export the processed audio\n",
    "    processed_audio.export(output_path, format='mp3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First identify merged files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_merged_files(folder_path, gap_threshold=15, start_word_cooldown=15):\n",
    "    \"\"\"\n",
    "    Identify audio files that are likely merged from multiple conversations.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing audio files.\n",
    "    gap_threshold (int): Time threshold in seconds to identify gaps indicating separate conversations.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains the file path and a list of timestamps where merges likely occur.\n",
    "    \"\"\"\n",
    "\n",
    "    merged_files = []\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    for audio_file in folder_path.rglob('*.json'):\n",
    "\n",
    "        transcription_data = read_transcription_data(audio_file)\n",
    "        merged_details = []\n",
    "        last_end_conversation_time = None\n",
    "        last_start_conversation_time = None\n",
    "\n",
    "        for segment in transcription_data:\n",
    "            segment_text = segment['text'].lower().strip()\n",
    "            segment_start = float(segment['start'])\n",
    "\n",
    "            # Check for end-of-conversation words\n",
    "            for end_word in END_OF_CONV_WORDS:\n",
    "                if re.search(r'\\b' + re.escape(end_word) + r'\\b', segment_text):\n",
    "                    last_end_conversation_time = segment_start\n",
    "                    break\n",
    "\n",
    "            for start_word in START_OF_CONV_WORDS:\n",
    "                if re.search(r'\\b' + re.escape(start_word) + r'\\b', segment_text):\n",
    "                    if segment_start < 2:  # assuming 5 seconds as a threshold for the beginning\n",
    "                        continue\n",
    "                    time_since_last_end = segment_start - last_end_conversation_time if last_end_conversation_time is not None else float('inf')\n",
    "                    time_since_last_start = segment_start - last_start_conversation_time if last_start_conversation_time is not None else float('inf')\n",
    "                    if time_since_last_end <= gap_threshold and time_since_last_start > start_word_cooldown:\n",
    "                        print(audio_file, time_since_last_end, time_since_last_start)\n",
    "                        merged_details.append((segment_start, start_word))\n",
    "                        last_start_conversation_time = segment_start\n",
    "                        break\n",
    "\n",
    "        if merged_details:\n",
    "            merged_files.append((str(audio_file), [(detail[0], detail[1]) for detail in merged_details]))\n",
    "\n",
    "    if merged_files:\n",
    "        merged_files_folder = folder_path.parent / \"merged_files\"\n",
    "        merged_files_folder.mkdir(exist_ok=True)\n",
    "        for merged_file in merged_files:\n",
    "            source_path = Path(merged_file[0]).parent\n",
    "            dest_path = merged_files_folder / Path(merged_file[0]).parent.name\n",
    "            if not dest_path.exists():\n",
    "                shutil.copytree(source_path, dest_path)\n",
    "\n",
    "    return merged_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_files = identify_merged_files(transcription_folder)\n",
    "print(len(merged_files))\n",
    "merged_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut and save audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_save_audio_files(splited_files_folder, merged_files):\n",
    "    \"\"\"\n",
    "    Process each audio file to cut and save segments based on specified cutting times.\n",
    "\n",
    "    Args:\n",
    "    raw_audio_folder (str): Path to the folder containing raw audio files.\n",
    "    merged_files (list of tuples): Each tuple contains the file path and a list of cutting times.\n",
    "\n",
    "    This function processes each specified audio file, cutting it into segments at the specified times, and saves these segments as new audio files.\n",
    "    \"\"\"\n",
    "    splited_files_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    for file_path, cutting_times in merged_files:\n",
    "        file_path = Path(file_path)\n",
    "        y, sr = load_audio(file_path, sr=None)\n",
    "\n",
    "        # Initial start sample for the first segment\n",
    "        prev_cut_sample = 0\n",
    "        original_stem = file_path.stem\n",
    "\n",
    "        for _, (cut_time, _) in enumerate(cutting_times):\n",
    "            cut_sample = int(cut_time * sr)\n",
    "            audio_segment = split_audio(file_path, prev_cut_sample, cut_sample, sr)\n",
    "\n",
    "            # Determine new file name and title\n",
    "            audio = MP3(file_path)\n",
    "            title = audio['TIT2'][0] if 'TIT2' in audio else 'Unknown'\n",
    "            start_timestamp, end_timestamp = parse_timestamp_from_title(title)\n",
    "            new_start_timestamp = start_timestamp + pd.to_timedelta(prev_cut_sample / sr, unit='s')\n",
    "            new_end_timestamp = start_timestamp + pd.to_timedelta(cut_sample / sr, unit='s')\n",
    "            new_file_name = format_filename(new_start_timestamp, original_stem)\n",
    "            new_title = f\"{new_start_timestamp.strftime('%d/%m/%Y %H:%M:%S')} - {new_end_timestamp.strftime('%d/%m/%Y %H:%M:%S')}\"\n",
    "\n",
    "            # Save the audio segment\n",
    "            segment_file_path = splited_files_folder / new_file_name\n",
    "            save_audio_segment(segment_file_path, audio_segment, sr)\n",
    "\n",
    "            # Update metadata for the segment\n",
    "            copy_metadata(file_path, segment_file_path, new_title)\n",
    "\n",
    "            prev_cut_sample = cut_sample\n",
    "\n",
    "        # Handle the last segment from the last cut to the end of the file\n",
    "        last_segment = split_audio(file_path, prev_cut_sample, len(y), sr)\n",
    "        new_start_timestamp = start_timestamp + pd.to_timedelta(prev_cut_sample / sr, unit='s')\n",
    "        new_file_name = format_filename(new_start_timestamp, original_stem)\n",
    "        last_segment_file_path = splited_files_folder / new_file_name\n",
    "        new_title = f\"{new_start_timestamp.strftime('%d/%m/%Y %H:%M:%S')} - {end_timestamp.strftime('%d/%m/%Y %H:%M:%S')}\"\n",
    "        save_audio_segment(last_segment_file_path, last_segment, sr)\n",
    "\n",
    "        # Update metadata for the last segment\n",
    "        copy_metadata(file_path, last_segment_file_path, new_title)\n",
    "\n",
    "        # Optionally delete the original file's transcription folder\n",
    "        # shutil.rmtree(file_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_folder = DATA_FOLDER / 'splited_files'\n",
    "cut_and_save_audio_files(splited_folder, merged_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to rerun transcribe_all on those new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\transcribe_all.py --source_folder \"..\\splited_files\" --dest_folder \"..\\splited_files\" --move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a splited_files containing unmerged files, the next step is to identify files belonging to the same conversation and fuse them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then create audio dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_problematic_end(transcription_data, words, end_time, density_threshold=0.2, diversity_threshold=0.5):\n",
    "    # Find time of the last occurrence of the end_word\n",
    "    last_end_word_time = None\n",
    "    for segment in reversed(transcription_data):\n",
    "        if any(re.search(r'\\b' + re.escape(end_word) + r'\\b', segment['text'].lower()) for end_word in words):\n",
    "            last_end_word_time = segment['end']\n",
    "            break\n",
    "\n",
    "    if last_end_word_time is None:\n",
    "        return False\n",
    "\n",
    "    # Analyze word density and diversity after the last end word\n",
    "    remaining_segments = [seg for seg in transcription_data if seg['start'] >= last_end_word_time]\n",
    "    total_words = sum(len(seg['text'].split()) for seg in remaining_segments)\n",
    "    unique_words = len(set(word for seg in remaining_segments for word in seg['text'].split()))\n",
    "\n",
    "    remaining_time = end_time - last_end_word_time\n",
    "    word_density = total_words / remaining_time if remaining_time > 0 else 0\n",
    "    word_diversity = unique_words / total_words if total_words > 0 else 1\n",
    "\n",
    "    return word_density > density_threshold or word_diversity < diversity_threshold\n",
    "\n",
    "def create_audio_database(audio_files):\n",
    "    \"\"\"\n",
    "    Create a database of audio files with metadata and transcription data.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing audio files and their transcription data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing metadata and transcription data for each audio file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        try:\n",
    "            audio = MP3(audio_file)\n",
    "            title = audio['TIT2'][0] if 'TIT2' in audio else 'Unknown'\n",
    "            start_timestamp, end_timestamp = parse_timestamp_from_title(title)\n",
    "            audio_length = audio.info.length\n",
    "\n",
    "            transcription_path = audio_file.with_stem(audio_file.stem + '_transcription').with_suffix('.txt')\n",
    "            transcription_data_path = audio_file.with_name(audio_file.stem + '_segments_data.json')\n",
    "            transcription_data = read_transcription_data(transcription_data_path)\n",
    "\n",
    "            is_start_file = check_word_in_timeframe(transcription_data, START_OF_CONV_WORDS, 0, 10)\n",
    "            \n",
    "            is_end_file = check_word_in_timeframe(transcription_data, END_OF_CONV_WORDS, max(0, audio_length - 10), audio_length, is_end_segment=True)\n",
    "            is_problematic_end = check_for_problematic_end(transcription_data, END_OF_CONV_WORDS, audio_length, density_threshold=0.25, diversity_threshold=0.5)\n",
    "            is_end_file = is_end_file or is_problematic_end\n",
    "\n",
    "            is_complete = is_start_file and is_end_file\n",
    "\n",
    "            # If the file is complete, set is_start_file and is_end_file to False\n",
    "            if is_complete:\n",
    "                is_start_file = False\n",
    "                is_end_file = False\n",
    "\n",
    "            data.append({\n",
    "                \"File Name\": audio_file.stem,\n",
    "                \"File Path\": str(audio_file),\n",
    "                \"Transcription Path\": str(transcription_path) if transcription_path.exists() else None,\n",
    "                \"Start Timestamp\": start_timestamp,\n",
    "                \"End Timestamp\": end_timestamp,\n",
    "                \"Audio Length\": audio_length,\n",
    "                \"Is End File\": is_end_file,\n",
    "                \"Is Start File\": is_start_file,\n",
    "                \"Is Complete\": is_complete,\n",
    "                \"Precedent File\": None,\n",
    "                \"Next File\": None\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {audio_file}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Path</th>\n",
       "      <th>Transcription Path</th>\n",
       "      <th>Start Timestamp</th>\n",
       "      <th>End Timestamp</th>\n",
       "      <th>Audio Length</th>\n",
       "      <th>Is End File</th>\n",
       "      <th>Is Start File</th>\n",
       "      <th>Is Complete</th>\n",
       "      <th>Precedent File</th>\n",
       "      <th>Next File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023_1_15_20_27_15_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 20:27:15</td>\n",
       "      <td>2023-01-15 20:27:37</td>\n",
       "      <td>22.716</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023_1_15_20_27_38_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 20:27:38</td>\n",
       "      <td>2023-01-15 20:28:18</td>\n",
       "      <td>40.104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023_1_15_20_58_32_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 20:58:32</td>\n",
       "      <td>2023-01-15 21:00:33</td>\n",
       "      <td>120.816</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023_1_15_21_0_34_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:00:34</td>\n",
       "      <td>2023-01-15 21:02:41</td>\n",
       "      <td>126.972</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023_1_15_21_34_9_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:34:09</td>\n",
       "      <td>2023-01-15 21:35:17</td>\n",
       "      <td>67.572</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023_1_15_21_35_18_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:35:18</td>\n",
       "      <td>2023-01-15 21:35:24</td>\n",
       "      <td>6.360</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023_1_15_21_35_24_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:35:24</td>\n",
       "      <td>2023-01-15 21:37:50</td>\n",
       "      <td>146.230</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023_1_15_21_37_50_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:37:50</td>\n",
       "      <td>2023-01-15 21:39:00</td>\n",
       "      <td>70.210</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023_1_15_21_39_0_ch30</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>..\\audio_database\\test_audio_processing\\proces...</td>\n",
       "      <td>2023-01-15 21:39:00</td>\n",
       "      <td>2023-01-15 21:40:12</td>\n",
       "      <td>71.248</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Name                                          File Path  \\\n",
       "0  2023_1_15_20_27_15_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "1  2023_1_15_20_27_38_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "2  2023_1_15_20_58_32_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "3   2023_1_15_21_0_34_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "4   2023_1_15_21_34_9_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "5  2023_1_15_21_35_18_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "6  2023_1_15_21_35_24_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "7  2023_1_15_21_37_50_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "8   2023_1_15_21_39_0_ch30  ..\\audio_database\\test_audio_processing\\proces...   \n",
       "\n",
       "                                  Transcription Path     Start Timestamp  \\\n",
       "0  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 20:27:15   \n",
       "1  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 20:27:38   \n",
       "2  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 20:58:32   \n",
       "3  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:00:34   \n",
       "4  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:34:09   \n",
       "5  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:35:18   \n",
       "6  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:35:24   \n",
       "7  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:37:50   \n",
       "8  ..\\audio_database\\test_audio_processing\\proces... 2023-01-15 21:39:00   \n",
       "\n",
       "        End Timestamp  Audio Length  Is End File  Is Start File  Is Complete  \\\n",
       "0 2023-01-15 20:27:37        22.716        False           True        False   \n",
       "1 2023-01-15 20:28:18        40.104        False          False        False   \n",
       "2 2023-01-15 21:00:33       120.816        False           True        False   \n",
       "3 2023-01-15 21:02:41       126.972         True          False        False   \n",
       "4 2023-01-15 21:35:17        67.572        False          False        False   \n",
       "5 2023-01-15 21:35:24         6.360         True          False        False   \n",
       "6 2023-01-15 21:37:50       146.230        False          False         True   \n",
       "7 2023-01-15 21:39:00        70.210        False          False         True   \n",
       "8 2023-01-15 21:40:12        71.248        False          False         True   \n",
       "\n",
       "  Precedent File Next File  \n",
       "0           None      None  \n",
       "1           None      None  \n",
       "2           None      None  \n",
       "3           None      None  \n",
       "4           None      None  \n",
       "5           None      None  \n",
       "6           None      None  \n",
       "7           None      None  \n",
       "8           None      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "\n",
    "# if merged_files:\n",
    "#     merged_files_path_list = [Path(file_path).parent for file_path, _ in merged_files]\n",
    "#     audio_files = [audio_file for audio_file in transcription_folder.rglob('*.mp3') if audio_file.parent not in merged_files_path_list] \\\n",
    "#                 + [audio_file for audio_file in splited_folder.rglob('*.mp3')]    \n",
    "# else:\n",
    "#     audio_files = [audio_file for audio_file in transcription_folder.rglob('*.mp3') ] \\\n",
    "#                 + [audio_file for audio_file in splited_folder.rglob('*.mp3')]\n",
    "\n",
    "folder = Path(\"../audio_database/test_audio_processing/processed/\")\n",
    "audio_files = [audio_file for audio_file in folder.rglob('*.mp3') ]\n",
    "\n",
    "df = create_audio_database(audio_files)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['File Name'] == \"2022_1_4_0_2_37_ch25\") | (df['File Name'] == \"2022_1_4_0_4_15_ch25\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroup associated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_associated_files(df, time_delta=20):\n",
    "    \"\"\"\n",
    "    Identify groups of audio files that are associated based on their timestamps and the status of the file (start of conversation, end of conversation, neither).\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): A DataFrame containing audio file metadata, including start and end timestamps.\n",
    "    time_delta (int): The maximum time difference in seconds between the end of one file and the start of another for them to be considered associated.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains file paths of associated audio files. The files in each tuple are considered part of the same conversation or related sequence.\n",
    "    \n",
    "    This function analyzes the start and end timestamps of audio files to group them into conversations or sequences based on the specified time delta.\n",
    "    \"\"\"\n",
    "    associated_files = []\n",
    "\n",
    "    # Filter DataFrame for start, other, and end files\n",
    "    start_files = df[df['Is Start File']]\n",
    "    other_files = df[~df['Is End File'] & ~df['Is Start File'] & ~df['Is Complete']]\n",
    "    end_files = df[df['Is End File']]\n",
    "\n",
    "    for idx, start_row in start_files.iterrows():\n",
    "        end_time_beginning = start_row['End Timestamp']\n",
    "        if pd.isnull(end_time_beginning):\n",
    "            continue\n",
    "\n",
    "        # First check in other_files\n",
    "        other_file_found = None\n",
    "        for _, other_row in other_files.iterrows():\n",
    "            if start_row.iloc[0].split('_')[-1] != other_row.iloc[0].split('_')[-1]:\n",
    "                continue\n",
    "            start_time_other = other_row['Start Timestamp']\n",
    "            if pd.isnull(start_time_other):\n",
    "                continue\n",
    "\n",
    "            if 0 <= (start_time_other - end_time_beginning).total_seconds() <= time_delta:\n",
    "                other_file_found = other_row\n",
    "                break\n",
    "\n",
    "        # If an other_file is found, check for a corresponding file in file_ends\n",
    "        end_file_found = None\n",
    "        if other_file_found is not None:\n",
    "            end_time_other = other_file_found['End Timestamp']\n",
    "            for _, end_row in end_files.iterrows():\n",
    "                if start_row.iloc[0].split('_')[-1] != end_row.iloc[0].split('_')[-1]:\n",
    "                    continue\n",
    "                start_time_ending = end_row['Start Timestamp']\n",
    "                if pd.isnull(start_time_ending):\n",
    "                    continue\n",
    "\n",
    "                if 0 <= (start_time_ending - end_time_other).total_seconds() <= time_delta:\n",
    "                    end_file_found = end_row\n",
    "                    break\n",
    "\n",
    "            if end_file_found is not None:\n",
    "                associated_files.append((start_row['File Path'], other_file_found['File Path'], end_file_found['File Path']))\n",
    "            else:\n",
    "                associated_files.append((start_row['File Path'], other_file_found['File Path']))\n",
    "\n",
    "        # If no other_file is found, check directly in file_ends\n",
    "        elif other_file_found is None:\n",
    "            for _, end_row in end_files.iterrows():\n",
    "                if start_row.iloc[0].split('_')[-1] != end_row.iloc[0].split('_')[-1]:\n",
    "                    continue\n",
    "                start_time_ending = end_row['Start Timestamp']\n",
    "                if pd.isnull(start_time_ending):\n",
    "                    continue\n",
    "\n",
    "                if 0 <= (start_time_ending - end_time_beginning).total_seconds() <= time_delta:\n",
    "                    associated_files.append((start_row['File Path'], end_row['File Path']))\n",
    "                    break\n",
    "\n",
    "    return associated_files\n",
    "\n",
    "associated_files = find_associated_files(df)\n",
    "for files in associated_files:\n",
    "    print(f\"Associated files: {', '.join(files)}\")\n",
    "print(len(associated_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy2\n",
    "\n",
    "def merge_audio_segments(audio_tuples, output_folder, segment_length=5):\n",
    "    for tuple_index, audio_tuple in enumerate(audio_tuples):\n",
    "        # Create a subfolder for each merged audio\n",
    "        subfolder_path = Path(output_folder) / f\"merged_audio_{tuple_index}\"\n",
    "        subfolder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        for i in range(len(audio_tuple) - 1):\n",
    "            audio_file_path = Path(audio_tuple[i])\n",
    "            next_audio_file_path = Path(audio_tuple[i + 1])\n",
    "\n",
    "            if not audio_file_path.exists() or not next_audio_file_path.exists():\n",
    "                print(f\"File not found: {audio_file_path} or {next_audio_file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load the current and next audio files using librosa\n",
    "            current_audio, sr_current = librosa.load(audio_file_path, sr=None)\n",
    "            next_audio, sr_next = librosa.load(next_audio_file_path, sr=None)\n",
    "\n",
    "            # Ensure both files have the same sample rate\n",
    "            if sr_current != sr_next:\n",
    "                raise ValueError(\"Sample rates do not match\")\n",
    "\n",
    "            # Convert segment length from seconds to samples\n",
    "            segment_length_samples = segment_length * sr_current\n",
    "\n",
    "            # Extract segments\n",
    "            current_audio_segment = current_audio[-min(segment_length_samples, len(current_audio)):]\n",
    "            next_audio_segment = next_audio[:min(segment_length_samples, len(next_audio))]\n",
    "\n",
    "            # Merge the segments\n",
    "            merged_segment = np.concatenate((current_audio_segment, next_audio_segment))\n",
    "\n",
    "            copy2(audio_tuple[i], subfolder_path)\n",
    "            copy2(audio_tuple[i + 1], subfolder_path)\n",
    "\n",
    "            # Save the merged segment in the subfolder using soundfile\n",
    "            merged_output_path = os.path.join(subfolder_path, f\"merged_segment_{i}.wav\")\n",
    "            sf.write(merged_output_path, merged_segment, sr_current)\n",
    "\n",
    "\n",
    "merge_audio_segments(associated_files, DATA_FOLDER / 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy grouped files and merge the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_associated_files(associated_files, df, fused_audio_folder):\n",
    "    \"\"\"\n",
    "    Merge associated audio files and save it on the raw_audio_folder\n",
    "\n",
    "    Args:\n",
    "    associated_files (list of tuples): Each tuple contains file paths of associated audio files.\n",
    "    df (pandas.DataFrame): A DataFrame containing audio file metadata.\n",
    "    raw_audio_folder (str): Path to the folder where the grouped and merged audio files will be stored.\n",
    "\n",
    "    This function processes each group of associated files, merges their audio content, and saves the merged audio in the specified folder. It also updates the metadata for the merged files based on the group's start and end timestamps.\n",
    "    \"\"\"\n",
    "\n",
    "    fused_audio_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    for group in associated_files:\n",
    "        # Create a unique folder for each group\n",
    "\n",
    "        audio_files = []\n",
    "        start_timestamp = None\n",
    "        end_timestamp = None\n",
    "\n",
    "        for file_path in group:        \n",
    "            # Add file to list for merging\n",
    "            audio_files.append(file_path)\n",
    "\n",
    "            # Extract timestamps for merged file metadata\n",
    "            file_info = df[df['File Path'] == file_path].iloc[0]\n",
    "            if start_timestamp is None or file_info['Start Timestamp'] < start_timestamp:\n",
    "                start_timestamp = file_info['Start Timestamp']\n",
    "            if end_timestamp is None or file_info['End Timestamp'] > end_timestamp:\n",
    "                end_timestamp = file_info['End Timestamp']\n",
    "\n",
    "            # Delete original audio\n",
    "            # original_audio = raw_audio_folder / Path(file_path).name\n",
    "            # original_audio.unlink()\n",
    "\n",
    "        # Merge and save audio\n",
    "        fused_audio, sample_rate = merge_audios(audio_files)\n",
    "        fused_file_path = fused_audio_folder / Path(audio_files[0]).name\n",
    "        save_audio_segment(fused_file_path, fused_audio, sample_rate)\n",
    "        \n",
    "        # Copy metadata from the beginning file to the merged file\n",
    "        start_timestamp = start_timestamp.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        end_timestamp = end_timestamp.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "        new_title = f\"{start_timestamp} - {end_timestamp}\"\n",
    "        copy_metadata(group[0], fused_file_path, new_title)\n",
    "\n",
    "        # Delete old transcription folder\n",
    "        # for file_path in group:\n",
    "        #     shutil.rmtree(Path(file_path).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "fused_audio_folder = DATA_FOLDER / \"fused_files/\"\n",
    "merge_associated_files(associated_files, df, fused_audio_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun again transcribe_all on the final new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\transcribe_all.py --source_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test\\\" --dest_folder \"C:\\Users\\Thib\\PycharmProjects\\ECHO\\audio_database\\raw_mp3_test_transcription\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy to processed folder\n",
    "\n",
    "processed_files = DATA_FOLDER / \"processed_files\"\n",
    "processed_files.mkdir(exist_ok=True)\n",
    "\n",
    "associated_files_list = [Path(path).stem for path_tuple in associated_files for path in path_tuple]\n",
    "transcription_folder_list = list(transcription_folder.iterdir())\n",
    "fused_folder_list = list(fused_audio_folder.iterdir())\n",
    "splited_folder_list = list(splited_folder.iterdir())\n",
    "\n",
    "for folder in fused_folder_list:\n",
    "    shutil.copytree(folder, processed_files / folder.name)\n",
    "    \n",
    "for folder in splited_folder_list:\n",
    "    if folder.name not in associated_files_list:\n",
    "        shutil.copytree(folder, processed_files / folder.name)\n",
    "\n",
    "for folder in transcription_folder_list:\n",
    "    if folder.name not in associated_files_list:\n",
    "        try:\n",
    "            shutil.copytree(folder, processed_files / folder.name)\n",
    "        except FileExistsError as e:\n",
    "            continue                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
